# 2026-02-01 - Daily Notes

## Overemployed & Job Scraping Research Session

### Research Completed
- Deep research on Overemployed (OE) strategy for UK
- Nick Saraev's automation methods and n8n workflows
- Salesforce Hiring Tracker service opportunity
- Job scraping automation systems

### Key Findings
1. **UK OE Requirements**: Fully remote jobs only, separate hardware, separate calendars, HMRC fine with multiple PAYE jobs
2. **Nick Saraev's Method**: Multi-page scraping + AI analysis = 5-10% response rates (vs 1-2% standard)
3. **Free Templates**: Cold Email Icebreaker Generator, Upwork Proposals, LinkedIn Connection Requests
4. **Tools Cost**: ~$150-200/month (n8n, Apollo.io, Apify, OpenAI)

### Files Created
- `/root/clawd/memory/overemployed-job-scraping-research.md` (464 lines)
- Updated `/root/clawd/memory/COMPLETE_IDEAS_LIST.md` with 5 new ideas (now 45 total)

### New Ideas Added
- Personal OE Strategy
- Nick Saraev Job Scraping Methods
- Salesforce Hiring Tracker Service (Bluprintx)
- Remote Job Scraping Subscription
- Job Application Automation (White-Label)

### Agent Tasks Ready
- Build Nick Saraev-style Job Application Automation
- Focus: Personal OE use case + Bluprintx service potential

### Key Resources
- r/overemployed, r/OveremployedUK
- https://n8n.io/creators/nicksaraev/
- https://www.youtube.com/@nicksaraev

---

## Debt Elimination Plan
- Target: Clear ¬£100,045.43 by February 2027
- Monthly available: ¬£4,624 after all expenses/tax savings
- Priority: HMRC ‚Üí iwoca (20.9%) ‚Üí Funding Circle (20.9%) ‚Üí Zopa ‚Üí Novuna ‚Üí M&S ‚Üí HSBC ‚Üí Credit cards

---

## In Progress
- Freeagent KSD company access (awaiting support response)
- Oktopost API bug fixes (awaiting support response)
- Bannerbear ‚Üí Canva integration workflow
- Morning Briefing System (needs brain dump)

---

## Blocked
- Cannot test Oktopost fixes until support responds
- Need user API keys for Bannerbear, Canva OAuth
- Token returns Stripped Media instead of KSD

---

## Next Actions
1. Set up n8n.io account (free)
2. Import Nick Saraev's icebreaker workflow
3. Set up Apify LinkedIn Jobs scraper
4. Create Google Sheets CRM template
5. Build Job Application Automation workflow

---

## Financial Summary (Feb 1)
- Kobestarr Starling: ¬£1,036.04
- Stripped Media Starling + Freeagent: ¬£2,457.06
- Personal HSBC: Overdrawn (-¬£1,300 to -¬£2,100)
- Total Available: ~¬£3,493 (excl. personal HSBC)

---

## Debt Breakdown
- Personal: ¬£45,894.12
- Business: ¬£19,151.31
- HMRC: ¬£35,000
- **Total: ¬£100,045.43**

---

## Ideas Count: 45
- BUILT: 5
- IN PROGRESS: 2
- RESEARCH COMPLETE: 13
- CONCEPTS: 6
- NOT STARTED: 19

---

## Reddit-Researcher Project (NEW)

**Goal:** Build a tool to find validated startup ideas and ICP leads from Reddit

**Inspired by:** Greg's 4-step process from video transcription (8vXoI7lUroQ)

### The 4-Step Process (from video)

1. **Find trending subreddits** (10K-100K members) - "why now" opportunities
2. **Analyze problems & solutions** - Use AI to find patterns
3. **Find creators/influencers** - Perplexity.ai or manual YouTube search
4. **Build MVP** - Wireframe based on insights

### Alternative Uses
- **ICP Research** - Find potential customers discussing problems
- **Content Ideas** - Top-performing posts reveal what audiences want
- **Competitive Analysis** - See what solutions people already use

### Technical Approach

**Option A: PRAW (Python Reddit API Wrapper)**
- Free, but rate limited
- Good for testing/MVP
- `pip install praw`

**Option B: Apify Reddit Scraper**
- `apify.com/claredigital/reddit-scraper`
- Paid, but unlimited
- Date filters, score thresholds, nested comments

**Option C: Hybrid**
- PRAW for subreddit discovery/metadata
- Apify for deep comment scraping
- OpenAI for pattern analysis

### Tools We Have
- Apify (existing integration)
- OpenAI API (existing)
- UniScribe (existing)

### Next Steps
1. Research PRAW API limits
2. Create subreddit discovery script (find 10K-100K growing)
3. Build comment scraper for problem/solution extraction
4. Add AI pattern analysis (similar to Gummy Search summaries)
5. Export to structured format (Google Sheets, Notion)

### Naming
- **Reddit-Researcher** - Main tool
- **ICP-Finder** - Lead generation variant
- **Startup-Idea-Miner** - Startup discovery variant


---

## PEER REVIEW PROCESS (PERSISTENT)

### Git Hook Setup
- Location: `.git/hooks/post-push`
- Triggers on EVERY commit and push

### Two-Step Review Workflow

**STEP 1: Code Review (by Codex agent)**
- Uses: CODE_REVIEW_PROMPT.md
- Checks: Logging, Error Handling, TypeScript, Production Readiness, React/Hooks, Performance, Security, Architecture, Python specifics
- Output: List of issues found with severity levels

**STEP 2: Peer Review (by team lead - another model)**
- Uses: PEER_REVIEW_PROMPT.md
- Validates: Each Codex finding (verify code, explain invalid findings)
- Output: Confirmed issues + invalid findings + prioritized fix plan

### Key Prompts
- **CODE_REVIEW_PROMPT.md** - What Codex checks for
- **PEER_REVIEW_PROMPT.md** - How I validate Codex findings

### PEER_REVIEW_PROMPT.md Template

```
## Peer Review Analysis

### Findings Confirmed as VALID (Will Fix)
| Issue | Severity | Fix Plan |
|-------|----------|----------|
|       |          |          |

### Findings INVALIDATED (With Explanations)
| Finding | Why It's Invalid |
|---------|------------------|
|         |                  |

### Priority Action Plan
1. [HIGH] 
2. [MEDIUM] 
3. [LOW] 
```

### Critical Rules
1. **Use both prompts** - Every review must use CODE_REVIEW_PROMPT.md AND PEER_REVIEW_PROMPT.md
2. **Verify before accepting** - Check actual code, don't assume Codex is correct
3. **Explain invalid findings** - Clear reasoning, not dismissals
4. **Prioritize fixes** - Not all issues are equal
5. **Full workflow on EVERY push** - Code review ‚Üí Peer review ‚Üí Summary


---

## Reddit Parasite SEO Project (NEW)

**Goal:** Use Reddit's DA 91 to rank content and get free traffic/leads

**Origin:** YouTube video (jMEhA3vhuuQ) - "Claude + Reddit AI Automation"

**Structure:**
```
reddit-parasite-seo/
‚îú‚îÄ‚îÄ README.md           # Knowledge base
‚îú‚îÄ‚îÄ transcript.txt      # Full transcription
‚îú‚îÄ‚îÄ raw.json            # UniScribe raw data
‚îî‚îÄ‚îÄ url.txt             # Source URL
```

**Key 4-Step Process:**
1. Create subreddit around your niche
2. Generate content with Claude AI
3. Quality control (critical - AI hallucinates!)
4. Post consistently + measure

**Tools:**
- Make.com auto-blogger
- Claude for content
- Proxies for Reddit accounts
- YouTube embeds for retargeting

**Metrics:**
- 25K visitors/month (example community)
- 1,300+ leads/week
- Immediate traffic (vs months for traditional SEO)

**Ignore:** Sales pitches about AI Profit boardroom, AI Money Lab


---

## Daily Briefing System (Active)

Set up 3 automated briefings delivered to WhatsApp:

### Morning Briefing - 6:35 AM UK
- Daily stats (emails, calendar, weather)
- Top priorities
- Financial check
- Personal (Mylo, appointments)
- Robyn's autonomous work queue

### Lunchtime Check-in - 12:35 PM UK
- LinkedIn post check (typically goes live 12:34 UK)
- Morning progress review
- Afternoon plan
- Quick wins

### End of Day Roundup - 9:35 PM UK
- Today's checklist completion
- Mylo prep check (clothes washed & packed)
- Tomorrow's priorities
- Robyn's night tasks (what to work on while sleeping)
- Wins and reflections

### Cron Job IDs
- Morning: a1f5fcff-d96b-4bb1-a6ae-7c8a323e2a79
- Lunchtime: 4a8755a8-bf1a-46a4-9a3e-0a4cdb17f2bd
- End of Day: 73ca532c-70fe-4bfa-994a-614bab158083


---

## NEW IDEA: PR Agency Outreach

**Pitch:** "I built Twiggy's website, I can do the same for your clients"

**Target ICPs:**
- PR agencies
- Publicists  
- Talent agencies

**Approach:**
- Research their pain points on Reddit (r/PR, r/marketing)
- Use Twiggy as case study
- Offer website audit + build service

**Connection to Reddit-Researcher:**
- Use research workflow to find hot prospects
- Monitor subreddits for hiring/funding announcements
- Build outreach templates based on insights

**Next Step:**
1. Transcribe Twiggy website case study
2. Research PR agency subreddits
3. Build outreach template


---

## Ideas Pipeline Tracking

**Current Count:** 21 active ideas (as of Feb 1, 2026)

**Tracking Status:**
- Built: 5
- In Progress: 2
- Research Complete: 13
- Concepts: 6
- Not Started: 19

**Morning Briefing Include:**
- Active ideas count
- Status breakdown
- Top priorities from ideas list

**Command to get count:**
```bash
grep -E "^### [0-9]" /root/clawd/IDEAS.md | wc -l
```


---

## Daily Schedule Structure (Active)

| Time (UK) | Briefing | Focus |
|-----------|----------|-------|
| **6:35 AM** | ‚òÄÔ∏è Morning Briefing | **LIFE** - Personal, health, financial, Mylo |
| **9:30 AM** | üíº Daily Standup | **WORK** - 3 questions, blockers, action items |
| **12:35 PM** | üåô Lunchtime Check | Freelance: Upwork, Bark, Twine |
| **5:30 PM** | üåô End of Day | Mylo prep, priorities, Robyn's night tasks |

### Daily Standup Protocol (9:30 AM)
**Time-box:** 10-15 minutes max

**The 3 Questions:**
1. What did you do yesterday?
2. What will you do today?
3. Any blockers?

**Rules:**
- Minimalist reporting (concise updates)
- Blockers get addressed immediately after
- Complex issues ‚Üí offline follow-up
- Celebrate wins!
- Focus: "Are we on track for our goals?"

### Morning Briefing (6:35 AM)
**Focus:** Personal/life stuff
- Mylo schedule
- Health data (weight, Strava)
- Financial check
- Weather/plans
- Ideas pipeline count


---

## Credentials & APIs Blocker Tracking

**Missing Credentials:** 5 total

### üî¥ Priority 1: CRITICAL (Blockers)
1. **OpenAI API Key** - Memory search broken, cannot recall past work
   - Get: https://platform.openai.com/api-keys
   - Save to: `/root/.credentials/openai.json`

2. **Google API Credentials** - Memory embeddings broken
   - Get: https://console.cloud.google.com
   - Save to: `/root/.credentials/google.json`

### üü° Priority 2: IMPORTANT
3. **Strava API** - Morning health data (weight, activities)
4. **Apify Token** - Advanced web scraping

### üü¢ Priority 3: NICE TO HAVE
5. **Brave Search API** - Enhanced web search

### Morning Briefing & Standup Include:
- "üîê Credentials missing: 5"
- "‚ö†Ô∏è Top blocker: OpenAI API (memory broken)"
- "Action needed: Get OpenAI key to enable full autonomy"

### Robyn's Standup Reporting:
- "I'm blocked on memory recall without OpenAI API"
- "Cannot search past research without Google credentials"
- "Need these to work autonomously"

**Tracker file:** `/root/clawd/transcription-automation/CREDENTIALS_NEEDED.md`


---

## Date/Time Validation Protocol

**Why:** LLMs often get dates wrong. Confirm at start of each briefing.

**Morning Briefing includes:**
- üìÖ "Today is [DATE] - Please confirm"
- üïê "Time: [TIME] - Please confirm"
- ‚ö†Ô∏è "LLM Date Awareness: UNVERIFIED"

**After human confirms:**
- ‚úÖ Update memory with confirmed date
- Use confirmed date for all references

**Example flow:**
```
Robyn: "Good morning! Today is [DATE] - please confirm what day it is."
Human: "Sunday February 1st"
Robyn: "‚úÖ Confirmed: Sunday February 1st, 2026. Thank you!"
```

**Until trusted:**
- Always ask for date confirmation in briefings
- Cross-check any date references
- Don't assume I know the current date

**When trusted (after 5-7 confirmed days):**
- "LLM Date Awareness: TRUSTED"
- No longer need confirmation


---

## Mylo's Calendar Events

**File:** `/root/clawd/personal/mylo/CALENDAR_EVENTS.md`

### üèïÔ∏è Chamboree 2026 (Added Feb 1, 2026)

**Key Dates:**
- **Deposit Due:** December 1st, 2025 (¬£30)
- **Camp:** August 7th-9th, 2026 (Cubs section)
- **Contact:** Sue Wardle - 1stpoyntongsl@gmail.com / 07816 601179

**Action Items:**
1. Contact Sue to reserve place (BEFORE Dec 1st)
2. Pay ¬£30 deposit by Dec 1st
3. Set up reminder for deposit deadline

### Reminders to Create:
- Deposit reminder: December 1st, 2025
- 2-week warning before deposit
- Packing list reminder (1 week before August 7th)

### Media Tracking (Future):
- Film releases (IMDb/Letterboxd)
- TV shows
- New seasons
- Morning briefing check-in


---

## February 2, 2026 - MAJOR INFRASTRUCTURE DAY

### Credentials Secured Today ‚úÖ

| Service | Status | Location | Data |
|---------|--------|----------|------|
| **OpenAI API** | ‚úÖ Connected | `/root/.credentials/openai.json` | Memory search, embeddings |
| **Strava API** | ‚úÖ Connected | `/root/.credentials/strava.json` | Activities, YTD stats |
| **Withings API** | ‚úÖ Connected | `/root/.credentials/withings.json` | Weight tracking |
| **Google Vertex AI** | ‚úÖ Service account | `/root/.credentials/google.json` | Project: stone-nucleus-485511-u9 |

### Morning Briefing System Active

| Time (UK) | Briefing | Status |
|-----------|----------|--------|
| **6:35 AM** | ‚òÄÔ∏è Morning Briefing | ‚úÖ Active - Includes Strava + Withings |
| **9:30 AM** | üíº Daily Standup | ‚úÖ Active - 3 questions format |
| **12:35 PM** | üåô Lunchtime | ‚úÖ Active - Freelance checks |
| **5:30 PM** | üåô End of Day | ‚úÖ Active - Mylo prep |

### Data Sources Connected

| Source | What's Tracked | Last Data |
|--------|---------------|-----------|
| üèÉ **Strava** | Activities, YTD stats | 28 runs (97.4km), 14 rides (469.3km), last: Jan 31 |
| ‚öñÔ∏è **Withings** | Weight | 95.0 kg (Aug 28, 2024) |
| üìÖ **Calendar** | Mylo events | Chamboree Aug 7-9, deposit Dec 1 (¬£5) |

### Research Completed

| Project | Files | Status |
|---------|-------|--------|
| **Reddit Parasite SEO** | 6 videos + MASTER.md | ‚úÖ Complete |
| **Digg Parasite SEO** | 3 videos | ‚úÖ Complete |
| **Reddit-Researcher** | 1 video | üîÑ In Progress |
| **PR Agency Outreach** | - | üìã New idea |

### Code Review Workflow

**Files Created:**
- `CODE_REVIEW_PROMPT.md` - Codex review criteria
- `PEER_REVIEW_PROMPT.md` - Peer validation process
- `.git/hooks/post-push` - Auto-trigger on push

**Process:**
1. Git push ‚Üí Hook fires
2. Codex reviews code
3. Peer review validates
4. Summary to human

### Mylo Info (Corrected Feb 2)

| Field | Value |
|-------|-------|
| **Birthday** | April 20, 2020 |
| **Age (now)** | 5 years, 9 months |
| **Section (now)** | Squirrels (4-6 years) |
| **Age (Chamboree)** | 6 years, 3 months |
| **Section (Chamboree)** | Beavers (6-8 years) |
| **Deposit** | ¬£5 (Beavers rate) |
| **Deposit Due** | December 1st, 2025 |
| **Camp Dates** | August 7th-9th, 2026 |

### Files Created/Updated Today

- `/root/.credentials/openai.json` - OpenAI API key
- `/root/.credentials/strava.json` - Strava OAuth
- `/root/.credentials/withings.json` - Withings OAuth
- `/root/.credentials/google.json` - Google service account
- `/root/clawd/personal/mylo/CALENDAR_EVENTS.md` - Mylo calendar
- `/root/clawd/transcription-automation/PARASITE_SEO_MASTER.md` - Strategy guide
- `/root/clawd/transcription-automation/CREDENTIALS_NEEDED.md` - Tracker

### Ideas Pipeline

**Total:** 21 active ideas
- Built: 5
- In Progress: 2  
- Research Complete: 13
- Concepts: 6
- Not Started: 19

### Next Steps

1. ‚úÖ Credentials all connected
2. ‚úÖ Morning briefings active
3. üîÑ Add weight data fetch to morning briefing
4. üîÑ Restart OpenClaw to activate all features
5. üìã Build Reddit-Researcher tool
6. üìã Create PR agency outreach template

